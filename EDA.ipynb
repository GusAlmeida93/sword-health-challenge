{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import input_file_name,explode,split,col, concat_ws\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    [1 ,1323, {'satisfaction': 9, 'pain': 2, 'fatigue': 2}, '2020-06-25'],\n",
    "    [2 ,9032,{'satisfaction': 2, 'pain': 7, 'fatigue': 5}, '2020-06-30'],\n",
    "    [3 ,2331, {'satisfaction': 7, 'pain': 1, 'fatigue': 1}, '2020-07-05'],\n",
    "    [4 ,2303, {'satisfaction': 8, 'pain': 9, 'fatigue': 0}, '2020-07-12'],\n",
    "    [5 ,1323, {'satisfaction': 10, 'pain': 0, 'fatigue': 0}, '2020-07-09'],\n",
    "    [6 ,2331, {'satisfaction': 8, 'pain': 9, 'fatigue': 5}, '2020-07-20'],\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data, columns=['id', 'patient_id', 'scores', 'date'])\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with duckdb.connect('sword.db') as con:\n",
    "    con.sql('CREATE TABLE scores AS SELECT * FROM df')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────┬────────────┬─────────────────────────────────────────────────────────────┬─────────────────────┐\n",
      "│  id   │ patient_id │                           scores                            │        date         │\n",
      "│ int64 │   int64    │ struct(satisfaction integer, pain integer, fatigue integer) │    timestamp_ns     │\n",
      "├───────┼────────────┼─────────────────────────────────────────────────────────────┼─────────────────────┤\n",
      "│     1 │       1323 │ {'satisfaction': 9, 'pain': 2, 'fatigue': 2}                │ 2020-06-25 00:00:00 │\n",
      "│     2 │       9032 │ {'satisfaction': 2, 'pain': 7, 'fatigue': 5}                │ 2020-06-30 00:00:00 │\n",
      "│     3 │       2331 │ {'satisfaction': 7, 'pain': 1, 'fatigue': 1}                │ 2020-07-05 00:00:00 │\n",
      "│     4 │       2303 │ {'satisfaction': 8, 'pain': 9, 'fatigue': 0}                │ 2020-07-12 00:00:00 │\n",
      "│     5 │       1323 │ {'satisfaction': 10, 'pain': 0, 'fatigue': 0}               │ 2020-07-09 00:00:00 │\n",
      "│     6 │       2331 │ {'satisfaction': 8, 'pain': 9, 'fatigue': 5}                │ 2020-07-20 00:00:00 │\n",
      "└───────┴────────────┴─────────────────────────────────────────────────────────────┴─────────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with duckdb.connect('sword.db') as con:\n",
    "    con.table('scores').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────┬─────────┬────────┐\n",
      "│ year  │  month  │  NPS   │\n",
      "│ int64 │ varchar │ double │\n",
      "├───────┼─────────┼────────┤\n",
      "│  2020 │ June    │    0.0 │\n",
      "│  2020 │ July    │    0.5 │\n",
      "└───────┴─────────┴────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with duckdb.connect('sword.db') as con:\n",
    "    con.sql(\"\"\"\n",
    "                WITH unnested as (\n",
    "                    SELECT \n",
    "                    id\n",
    "                    ,patient_id\n",
    "                    ,date\n",
    "                    ,MONTHNAME(date) as month\n",
    "                    ,YEAR(date) as year\n",
    "                    ,CASE WHEN scores.satisfaction >= 8 THEN 'Promoter'\n",
    "                        ELSE 'Detractor'\n",
    "                    END as NPS\n",
    "                    FROM scores),\n",
    "                grouped as (SELECT\n",
    "                    year\n",
    "                    ,month\n",
    "                    ,COUNT(CASE WHEN NPS = 'Promoter' THEN 1 END) as Promoters\n",
    "                    ,COUNT(CASE WHEN NPS = 'Detractor' THEN 1 END) as Detractors\n",
    "                    ,COUNT(*) as Total\n",
    "                    FROM unnested\n",
    "                    GROUP BY year, month)\n",
    "                SELECT\n",
    "                    year\n",
    "                    ,month\n",
    "                    ,(Promoters - Detractors) / Total as NPS\n",
    "                FROM grouped\n",
    "                    \"\"\"\n",
    "                ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/26 03:50:20 WARN Utils: Your hostname, Gustavos-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.1.22 instead (on interface en0)\n",
      "24/08/26 03:50:20 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/08/26 03:50:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "      .master(\"local[10]\") \\\n",
    "      .appName(\"sword-health\") \\\n",
    "      .getOrCreate() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Dataset Source](https://huggingface.co/datasets/hakatiki/guttenberg-books-corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset source https://huggingface.co/datasets/hakatiki/guttenberg-books-corpus\n",
    "path = './books/'\n",
    "df = spark.read.option(\"recursiveFileLookup\", \"true\").text(path)\n",
    "df = df.withColumn(\"filename\", input_file_name())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 32:===================================================>    (12 + 1) / 13]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-------------+\n",
      "|word|  count|         text|\n",
      "+----+-------+-------------+\n",
      "|   a|1388639|  a = 1388639|\n",
      "|    |1181349|    = 1181349|\n",
      "|  az| 436808|  az = 436808|\n",
      "|   –| 344590|   – = 344590|\n",
      "|hogy| 285508|hogy = 285508|\n",
      "| nem| 233974| nem = 233974|\n",
      "|   s| 231370|   s = 231370|\n",
      "|  és| 205993|  és = 205993|\n",
      "|   A| 178977|   A = 178977|\n",
      "|  is| 158089|  is = 158089|\n",
      "| egy| 155425| egy = 155425|\n",
      "|mint|  84881| mint = 84881|\n",
      "|volt|  84663| volt = 84663|\n",
      "| meg|  82173|  meg = 82173|\n",
      "|csak|  81947| csak = 81947|\n",
      "|  ki|  75033|   ki = 75033|\n",
      "| azt|  74088|  azt = 74088|\n",
      "|  de|  67948|   de = 67948|\n",
      "| még|  67495|  még = 67495|\n",
      "|  Az|  66971|   Az = 66971|\n",
      "+----+-------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_count=(\n",
    "  df.withColumn('word', explode(split(col('value'), ' ')))\n",
    "    .groupBy('word')\n",
    "    .count()\n",
    "    .sort('count', ascending=False)\n",
    "    .withColumn('text', concat_ws(' = ', col('word'), col('count')))\n",
    ")\n",
    "df_count.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#df_count.select('text').repartition(1).write.text('output')\n",
    "df_count.select('text').toPandas().to_csv('output.txt', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
